{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException     \n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm \n",
    "\n",
    "import tensorflow as tf \n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import traceback\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "#클라이언트의 식별정보를 담은 헤더: 이거 추가해서 넣으면 봇으로 탐지 안 될 수 있음. \n",
    "#https://www.whatismybrowser.com/detect/what-is-my-user-agent/\n",
    "options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/119.0') \n",
    "# navigator.webdriver 탐지 피하기 \n",
    "# f12 > console > navigator.webdriver 입력 > false로 나오면 화면 접속 중인 client가 봇인지 아닌지 판별\n",
    "# 웹사이트마다 정책이 달라서 사용할 수 있는 보조 수단으로 생각\n",
    "options.add_argument('--disable-blink-features=AutomationControlled') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰 저장할 리스트 만들기 \n",
    "review_list = []\n",
    "#에러 목록 저장할 리스트 만들기: 에러 생기는 값들 저장해두기 \n",
    "error_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 webdriver 사용 가능한데 chrome이 메모리 많이 잡아먹음 -> 데이터가 만 단위 넘어가면\n",
    "# 브라우저도 메모리가 있어서 돌다가 안 돌아감\n",
    "# 파이어폭스 브라우저가 메모리 사용량이 더 적음 \n",
    "# browser = webdriver.Chrome()\n",
    "browser = webdriver.Firefox()\n",
    "\n",
    "#네이버쇼핑 url 열기 \n",
    "url = 'https://shopping.naver.com/home'\n",
    "browser.get(url)\n",
    "time.sleep(random.uniform(2,3)) # 잠시 멈추기 위한 장치\n",
    "\n",
    "#수집할 상품 키워드 \n",
    "product_keyword = '롱패딩'\n",
    "\n",
    "#검색어 입력 \n",
    "# browser.find_element(By.XPATH,'Xpath경로'): 우리가 연 브라우저에서 XPATH로 element를 찾는다는 뜻\n",
    "# f12 > 화살표 > 검색창에 갖다대고 > html에서 > copy > copy xpath\n",
    "# By.XPATH: XPATH로 찾겠다는 의미\n",
    "searchbox = browser.find_element(By.XPATH,'//*[@id=\"gnb-gnb\"]/div[2]/div/div[2]/div/div[2]/form/div[1]/div/input').send_keys(product_keyword)\n",
    "\n",
    "#돋보기 클릭 //*[@id=\"gnb-gnb\"]/div/div[1]/button/span\n",
    "search_icon = browser.find_element(By.XPATH,'//*[@id=\"gnb-gnb\"]/div[2]/div/div[2]/div/div[2]/form/div[1]/div/button[2]')\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 상품 수 :  1,465,420\n"
     ]
    }
   ],
   "source": [
    "# 맨 하단까지 스크롤해서 전체정보 다 가져오기 (동적 웹사이트)\n",
    "# https://stackoverflow.com/questions/20986631/how-can-i-scroll-a-web-page-using-selenium-webdriver-in-python\n",
    "# Get scroll height / 스크롤 전 스크롤의 위치 \n",
    "last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # 현재 화면에서 스크롤 가장 아래로 내림 \n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    # 새로운 페이지 로딩 될때까지 기다리기 \n",
    "    time.sleep(random.uniform(1.5,2))\n",
    "    # 새로운 스크롤 높이 변수로 저장 \n",
    "    new_height = browser.execute_script(\"return document.body.scrollHeight\")    \n",
    "    # print(last_height,'/',new_height)    \n",
    "    # 새로운 스크롤 위치와 이동 전 스크롤 위치 같으면(더 이상 스크롤이 늘어나지 않으면) 종료\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "#전체 상품 수\n",
    "all_pdt_num = browser.find_element(By.XPATH,'//*[@id=\"content\"]/div[1]/div[1]/ul/li[1]/a/span[1]').text\n",
    "print('전체 상품 수 : ',all_pdt_num)\n",
    "\n",
    "review_button = browser.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[2]/div/div[4]/div/div/div[2]/div[5]/a/em')\n",
    "review_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=================  리뷰 페이지 :  1  =================>\n",
      "-------------------------------------------------\n",
      "상품명 :  LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운 / 등록일 :  2023.11.\n",
      "총리뷰수 :  167\n",
      "마지막페이지 :  9\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "8 페이지\n",
      "9 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  올리브데올리브 폭스퍼 후드 다운 롱 패딩 YP3WH830 / 등록일 :  2023.10.\n",
      "총리뷰수 :  510\n",
      "마지막페이지 :  26\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "8 페이지\n",
      "9 페이지\n",
      "10 페이지\n",
      "11 페이지\n",
      "12 페이지\n",
      "13 페이지\n",
      "14 페이지\n",
      "15 페이지\n",
      "16 페이지\n",
      "17 페이지\n",
      "18 페이지\n",
      "19 페이지\n",
      "20 페이지\n",
      "21 페이지\n",
      "22 페이지\n",
      "23 페이지\n",
      "24 페이지\n",
      "25 페이지\n",
      "26 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  폴햄키즈 공용 구스다운 롱패딩 점퍼 PKD4JP3010 / 등록일 :  2023.11.\n",
      "총리뷰수 :  249\n",
      "마지막페이지 :  13\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "8 페이지\n",
      "9 페이지\n",
      "10 페이지\n",
      "11 페이지\n",
      "12 페이지\n",
      "13 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  폴햄 23FW 여성용 퀼팅 롱 경량 패딩 1종 / 등록일 :  2023.09.\n",
      "총리뷰수 :  1691\n",
      "마지막페이지 :  85\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "8 페이지\n",
      "9 페이지\n",
      "10 페이지\n",
      "11 페이지\n",
      "12 페이지\n",
      "13 페이지\n",
      "14 페이지\n",
      "15 페이지\n",
      "16 페이지\n",
      "17 페이지\n",
      "18 페이지\n",
      "19 페이지\n",
      "20 페이지\n",
      "21 페이지\n",
      "22 페이지\n",
      "23 페이지\n",
      "24 페이지\n",
      "25 페이지\n",
      "26 페이지\n",
      "27 페이지\n",
      "28 페이지\n",
      "29 페이지\n",
      "30 페이지\n",
      "31 페이지\n",
      "32 페이지\n",
      "33 페이지\n",
      "34 페이지\n",
      "35 페이지\n",
      "36 페이지\n",
      "37 페이지\n",
      "38 페이지\n",
      "39 페이지\n",
      "40 페이지\n",
      "41 페이지\n",
      "42 페이지\n",
      "43 페이지\n",
      "44 페이지\n",
      "45 페이지\n",
      "46 페이지\n",
      "47 페이지\n",
      "48 페이지\n",
      "49 페이지\n",
      "50 페이지\n",
      "51 페이지\n",
      "52 페이지\n",
      "53 페이지\n",
      "54 페이지\n",
      "55 페이지\n",
      "56 페이지\n",
      "57 페이지\n",
      "58 페이지\n",
      "59 페이지\n",
      "60 페이지\n",
      "61 페이지\n",
      "62 페이지\n",
      "63 페이지\n",
      "64 페이지\n",
      "65 페이지\n",
      "66 페이지\n",
      "67 페이지\n",
      "68 페이지\n",
      "69 페이지\n",
      "70 페이지\n",
      "71 페이지\n",
      "72 페이지\n",
      "73 페이지\n",
      "74 페이지\n",
      "75 페이지\n",
      "76 페이지\n",
      "77 페이지\n",
      "78 페이지\n",
      "79 페이지\n",
      "80 페이지\n",
      "81 페이지\n",
      "82 페이지\n",
      "83 페이지\n",
      "84 페이지\n",
      "85 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  듀엘 폭스퍼 후드 구스다운 롱패딩 D234PSG270 155512 / 등록일 :  2023.08.\n",
      "총리뷰수 :  138\n",
      "마지막페이지 :  7\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  올젠 남성 경량 패딩 다운점퍼 숏 롱 고밀도 중기장 덕다운 점퍼 ZOC4FP1306 / 등록일 :  2023.12.\n",
      "총리뷰수 :  302\n",
      "마지막페이지 :  16\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "8 페이지\n",
      "9 페이지\n",
      "10 페이지\n",
      "11 페이지\n",
      "12 페이지\n",
      "13 페이지\n",
      "14 페이지\n",
      "15 페이지\n",
      "16 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  벤시몽 23FW 여성 누아주 롱패딩 점퍼 / 등록일 :  2023.11.\n",
      "총리뷰수 :  1292\n",
      "마지막페이지 :  65\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "8 페이지\n",
      "9 페이지\n",
      "10 페이지\n",
      "11 페이지\n",
      "12 페이지\n",
      "13 페이지\n",
      "14 페이지\n",
      "15 페이지\n",
      "16 페이지\n",
      "17 페이지\n",
      "18 페이지\n",
      "19 페이지\n",
      "20 페이지\n",
      "21 페이지\n",
      "22 페이지\n",
      "23 페이지\n",
      "24 페이지\n",
      "25 페이지\n",
      "26 페이지\n",
      "27 페이지\n",
      "28 페이지\n",
      "29 페이지\n",
      "30 페이지\n",
      "31 페이지\n",
      "32 페이지\n",
      "33 페이지\n",
      "34 페이지\n",
      "35 페이지\n",
      "36 페이지\n",
      "37 페이지\n",
      "38 페이지\n",
      "39 페이지\n",
      "40 페이지\n",
      "41 페이지\n",
      "42 페이지\n",
      "43 페이지\n",
      "44 페이지\n",
      "45 페이지\n",
      "46 페이지\n",
      "47 페이지\n",
      "48 페이지\n",
      "49 페이지\n",
      "50 페이지\n",
      "51 페이지\n",
      "52 페이지\n",
      "53 페이지\n",
      "54 페이지\n",
      "55 페이지\n",
      "56 페이지\n",
      "57 페이지\n",
      "58 페이지\n",
      "59 페이지\n",
      "60 페이지\n",
      "61 페이지\n",
      "62 페이지\n",
      "63 페이지\n",
      "64 페이지\n",
      "65 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  폴햄키즈 구스다운 롱패딩 PKD4JP3010 / 등록일 :  폴햄키즈\n",
      "총리뷰수 :  1\n",
      "마지막페이지 :  1\n",
      "1 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  올리브데올리브 폭스퍼 벨티드 롱 다운패딩코트 YP3WH830 / 등록일 :  폴햄키즈\n",
      "총리뷰수 :  191\n",
      "마지막페이지 :  10\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "8 페이지\n",
      "9 페이지\n",
      "10 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  듀엘 후드 폭스퍼 벨티드 롱패딩 L234PSG046 / 등록일 :  2023.12.\n",
      "총리뷰수 :  70\n",
      "마지막페이지 :  4\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  프로젝트엠 공용 메가히트 덕다운 롱 패딩점퍼 EPD4JD3977 / 등록일 :  2023.10.\n",
      "총리뷰수 :  395\n",
      "마지막페이지 :  20\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "8 페이지\n",
      "9 페이지\n",
      "10 페이지\n",
      "11 페이지\n",
      "12 페이지\n",
      "13 페이지\n",
      "14 페이지\n",
      "15 페이지\n",
      "16 페이지\n",
      "17 페이지\n",
      "18 페이지\n",
      "19 페이지\n",
      "20 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  폴햄키즈 공용 에어구스 롱패딩 PKC4JP3010 / 등록일 :  2023.10.\n",
      "총리뷰수 :  33\n",
      "마지막페이지 :  2\n",
      "1 페이지\n",
      "2 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  폴햄 23FW 알래스카 롱패딩 오리털 점퍼1종 남여공용 / 등록일 :  2023.10.\n",
      "총리뷰수 :  48\n",
      "마지막페이지 :  3\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  헤지스키즈 아동용 롱패딩 에센셜 덕다운 벤치파카 HTW71JN01G / 등록일 :  헤지스키즈\n",
      "총리뷰수 :  36\n",
      "마지막페이지 :  2\n",
      "1 페이지\n",
      "2 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  베네통 양털카라구스롱패딩 BAPDB2361 / 등록일 :  2023.11.\n",
      "총리뷰수 :  27\n",
      "마지막페이지 :  2\n",
      "1 페이지\n",
      "2 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  르까프 227103 Lecaf르까프 23FW 남녀공용 롱패딩 / 등록일 :  2023.11.\n",
      "총리뷰수 :  518\n",
      "마지막페이지 :  26\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "8 페이지\n",
      "9 페이지\n",
      "10 페이지\n",
      "11 페이지\n",
      "12 페이지\n",
      "13 페이지\n",
      "14 페이지\n",
      "15 페이지\n",
      "16 페이지\n",
      "17 페이지\n",
      "18 페이지\n",
      "19 페이지\n",
      "20 페이지\n",
      "21 페이지\n",
      "22 페이지\n",
      "23 페이지\n",
      "24 페이지\n",
      "25 페이지\n",
      "26 페이지\n",
      "<=================  리뷰 페이지 :  2  =================>\n",
      "-------------------------------------------------\n",
      "상품명 :  타미힐피거 여성 덕다운 롱 패딩 후드 코트 / 등록일 :  2023.11.\n",
      "총리뷰수 :  21\n",
      "마지막페이지 :  2\n",
      "1 페이지\n",
      "2 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  듀엘 벨티드 구스다운 후드 롱 패딩 점퍼 L234PSG052 / 등록일 :  2023.10.\n",
      "총리뷰수 :  11\n",
      "마지막페이지 :  1\n",
      "1 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  셀렙샵 에디션 23FW 프리미엄 헝가리구스 롱 패딩 / 등록일 :  2023.11.\n",
      "총리뷰수 :  322\n",
      "마지막페이지 :  17\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "4 페이지\n",
      "5 페이지\n",
      "6 페이지\n",
      "7 페이지\n",
      "8 페이지\n",
      "9 페이지\n",
      "10 페이지\n",
      "11 페이지\n",
      "12 페이지\n",
      "13 페이지\n",
      "14 페이지\n",
      "15 페이지\n",
      "16 페이지\n",
      "17 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  스톤아일랜드 크링클랩스 롱 패딩 v0029 791570323 / 등록일 :  2023.11.\n",
      "총리뷰수 :  2\n",
      "마지막페이지 :  1\n",
      "1 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  올리비아로렌 구스다운 롱패딩 VOPKDXWB111-A 33671922 / 등록일 :  올리비아로렌\n",
      "총리뷰수 :  26\n",
      "마지막페이지 :  2\n",
      "1 페이지\n",
      "2 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  K2 롱패딩 여성 수지 TV 광고 앨리스 롱 구스 다운 점퍼 자켓 시그니처 앨리스 ALICE W KWW21566 / 등록일 :  K2\n",
      "총리뷰수 :  44\n",
      "마지막페이지 :  3\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  노스페이스 롱패딩 남녀공용 커플 학생 패딩 구스다운 하이브리드 캠핑 / 등록일 :  2023.10.\n",
      "총리뷰수 :  36\n",
      "마지막페이지 :  2\n",
      "1 페이지\n",
      "2 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  블랙야크 공용 2L 방수롱패딩 오리털 덕다운패딩 115 120 - / 등록일 :  2023.10.\n",
      "총리뷰수 :  25\n",
      "마지막페이지 :  2\n",
      "1 페이지\n",
      "2 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  REEBOK NEW 리복 후드 롱패딩 남여 6LAYER / 등록일 :  2023.08.\n",
      "총리뷰수 :  34\n",
      "마지막페이지 :  2\n",
      "1 페이지\n",
      "2 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  듀엘 폭스퍼 트리밍 롱 구스다운 패딩 L234PSG048 / 등록일 :  2023.10.\n",
      "총리뷰수 :  53\n",
      "마지막페이지 :  3\n",
      "1 페이지\n",
      "2 페이지\n",
      "3 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  폴햄키즈 키즈 구스다운 롱패딩 PKD4JP3010 / 등록일 :  2024.01.\n",
      "총리뷰수 :  9\n",
      "마지막페이지 :  1\n",
      "1 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  온앤온 폭스퍼 구스다운 롱패딩 NJP3WHC08 / 등록일 :  2023.12.\n",
      "총리뷰수 :  8\n",
      "마지막페이지 :  1\n",
      "1 페이지\n",
      "-------------------------------------------------\n",
      "상품명 :  씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191 / 등록일 :  2023.11.\n",
      "총리뷰수 :  36\n",
      "마지막페이지 :  2\n",
      "1 페이지\n",
      "2 페이지\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------- 여러 상품의 리뷰 수집하기  --------------------------------- #\n",
    "for pdt_page in range(1,3): #임시로 3페이지까지. 전체 페이지 다 긁을거면 all_pdt_num 활용 \n",
    "    print( '<================= ', '리뷰 페이지 : ',pdt_page, ' =================>')\n",
    "    time.sleep(random.uniform(2,3))\n",
    "# --------------------------------- 한 페이지의 리뷰 다 가져오기 --------------------------------- #\n",
    "    for pdt_num in range(4,47):\n",
    "        time.sleep(random.uniform(3,4))\n",
    "        try: \n",
    "            xpath_1 = '//*[@id=\"content\"]/div[1]/div[2]/div/div[{0}]/div/div/div[3]/div/a'\n",
    "            name_tag = browser.find_element(By.XPATH,xpath_1.format(pdt_num)).text\n",
    "            try : # 어디서 에러 발생할 지 모르니까 전체 try-except 걸기\n",
    "                # 쇼핑몰별 최저가 텍스트로 조건 걸기 -> {0}으로 순서 표시\n",
    "                # 이걸로 시도해보자: try문 걸기 (연결 페이지 구조 다르면 작동 안 됨)\n",
    "                if name_tag == '쇼핑몰별 최저가':  #'쇼핑몰별 최저가' 링크가 아닌 기타 링크일 페이지 구조가 다르므로 스킵\n",
    "                    review_button = browser.find_element(By.XPATH,'//*[@id=\"content\"]/div[1]/div[2]/div/div[{0}]/div/div/div[2]/div[5]/a/em'.format(pdt_num))\n",
    "                    review_button.click()\n",
    "                    '''\n",
    "                    # div[1],[2],[3] 은 광고 상품이라 4부터 시작함.\n",
    "                    //*[@id=\"content\"]/div[1]/div[2]/div/div[4]/div/div/div[2]/div[5]/a/em #페이지 가장 위 첫 상품 \n",
    "                    //*[@id=\"content\"]/div[1]/div[2]/div/div[5]/div/div/div[2]/div[5]/a/em\n",
    "                    //*[@id=\"content\"]/div[1]/div[2]/div/div[6]/div/div/div[2]/div[5]/a/em\n",
    "                    //*[@id=\"content\"]/div[1]/div[2]/div/div[7]/div/div/div[2]/div[5]/a/em #페이지 가장 아래 마지막 상품 \n",
    "                    '''\n",
    "                    # if문 성공했을시:\n",
    "                    # --------------------------------- 상품 하나의 리뷰 가져오기 --------------------------------- #\n",
    "                    ### !새 탭으로 이동 (리뷰 누르면 새로운 창으로 열림) \n",
    "                    time.sleep(random.uniform(3,4))\n",
    "                    browser.switch_to.window(browser.window_handles[1])\n",
    "                    \n",
    "                    # 상품 기본정보 불러오기 - 여기도 에러 방지 위해 try문 입력\n",
    "                    # 근데 xpath 어디서 가져온 건지 잘 모르겠음..\n",
    "                    try:\n",
    "                        pdt_name = browser.find_element(By.XPATH,'/html/body/div/div/div[2]/div[2]/div[1]/h2').text #상품명\n",
    "                    except :\n",
    "                        None\n",
    "                    try:\n",
    "                        upload_date = browser.find_element(By.XPATH,'/html/body/div/div/div[2]/div[2]/div[1]/div[2]/span[2]/em').text #등록일\n",
    "                    except:\n",
    "                        None\n",
    "                    \n",
    "                    print('-------------------------------------------------')\n",
    "                    print('상품명 : ', pdt_name ,'/ 등록일 : ', upload_date)\n",
    "                    \n",
    "\n",
    "                    ### !리뷰 가져오기 \n",
    "                    ## 총 리뷰수\n",
    "                    # 페이지에 해당 숫자를 찾을 수 있는 곳이 여러 군데 있는데, 숫자를 분리하지 않고 통으로 가져올 수 있는 것 선택\n",
    "                    total_review_num = browser.find_element(By.XPATH,'//*[@id=\"section_review\"]/div[2]/div[2]/ul/li[1]/a/em')\n",
    "                    total_review_num_text = re.sub(r'[^0-9]', '' ,total_review_num.text ) #정규식으로 ( ) 제거: 숫자 제외한 나머지 값들 전부 제거 \n",
    "                    print(\"총리뷰수 : \", total_review_num_text) #중간중간 print 해주는게 좋음 \n",
    "                    \n",
    "                    \n",
    "                    ## 리뷰 마지막 페이지: 리뷰/페이지 수 해서 나머지 생기면 + 1 해서 남은 리뷰 수도 돌아가게 \n",
    "                    if int(total_review_num_text) % 20 == 0: # 딱 나눠 떨어지면 \n",
    "                        last_page = (int(total_review_num_text)//20) #총 리뷰 나누기 (몫만큼 알고리즘 돌리면 되니까) \n",
    "                    else:\n",
    "                        last_page = (int(total_review_num_text)//20) + 1 #총 리뷰 나누기 20 + 1 (나머지 리뷰 모으러 한 번 더 돌아가게)\n",
    "                    print(\"마지막페이지 : \", last_page)\n",
    "                    \n",
    "                    #한 상품 내에서 전체 페이지 돌아가면서 리뷰 수집하기 \n",
    "                    for page in range(1, last_page + 1 ): # for loop에서는 마지막 페이지 + 1\n",
    "                        time.sleep(random.uniform(2,3))\n",
    "                        print('{0} 페이지'.format(page)) # for문 돌아가면서 1 페이지, 2페이지, ... 이렇게 print됨\n",
    "                        \n",
    "                        #각 페이지 내의 리뷰 20개 가져오기 (1페이지의 20개)\n",
    "                        for i in range(1,21):\n",
    "\n",
    "                            try:\n",
    "                                별점 = browser.find_element(By.XPATH,'//*[@id=\"section_review\"]/ul/li[{0}]/div[1]/span[1]/span/span'.format(i)).get_attribute(\"style\")\n",
    "                                별점_num = int(re.findall(r'\\d+', 별점)[0])//20\n",
    "                                구매처 = browser.find_element(By.XPATH,'//*[@id=\"section_review\"]/ul/li[{0}]/div[1]/span[2]'.format(i)).text\n",
    "                                날짜 = browser.find_element(By.XPATH,'//*[@id=\"section_review\"]/ul/li[{0}]/div[1]/span[4]'.format(i)).text\n",
    "                                리뷰 = browser.find_element(By.XPATH,'//*[@id=\"section_review\"]/ul/li[{0}]/div[2]/div[1]/p'.format(i)).text\n",
    "                            except:\n",
    "                                별점 = None\n",
    "                                구매처 = None\n",
    "                                날짜 = None\n",
    "                                리뷰 = None\n",
    "                            #개별 리뷰의 각 요소를 빈 딕셔너리에 넣기 \n",
    "                            info_dict = {}\n",
    "                            info_dict['pdt_name'] = pdt_name \n",
    "                            info_dict['rating'] = 별점_num\n",
    "                            info_dict['store'] = 구매처\n",
    "                            info_dict['date'] = 날짜\n",
    "                            info_dict['review'] = 리뷰\n",
    "                            #info_dict를 리뷰 리스트에 추가 --> 나중에 한번에 데이터프레임으로 바꾸기 \n",
    "                            review_list.append(info_dict) \n",
    "                        \n",
    "                        time.sleep(random.uniform(1,2)) # 각 페이지별로 로딩 시간 걸어주기 \n",
    "                        \n",
    "                        # 앞서 한 페이지 완료했으니 이제 다음 페이지 버튼 클릭 \n",
    "                        try: # ex) 마지막 페이지가 9인 경우에는, //*[@id=\"section_review\"]/div[3]/a[10] 가 없어서 코드 에러가 발생하므로 에러 넘기기 \n",
    "                            #10 페이지에서는 '다음' 버튼을 눌러야 함 \n",
    "                            if page == 10 : #리뷰 화면에서 첫 페이지와, 2번째 페이지부터의 '다음'의 xpath가 다름 : 첫페이지는 a[11]\n",
    "                                next_button = browser.find_element(By.XPATH,'//*[@id=\"section_review\"]/div[3]/a[11]')\n",
    "                                next_button.click()\n",
    "                                # print('1번옵션')\n",
    "                            #20 페이지 이상부터 10단위마다 '다음' 누르기     \n",
    "                            elif page != 10 and page % 10 == 0 : #두번째 페이지 부터는 첫페이지는 a[12]\n",
    "                                next_button = browser.find_element(By.XPATH,'//*[@id=\"section_review\"]/div[3]/a[12]')\n",
    "                                next_button.click()\n",
    "                                # print('2번옵션')\n",
    "                            #10페이지 이하     \n",
    "                            elif page < 10: \n",
    "                                next_button = browser.find_element(By.XPATH,'//*[@id=\"section_review\"]/div[3]/a[{0}]'.format( (page % 10) + 1)) #\n",
    "                                next_button.click()   \n",
    "                                # print('3번옵션')\n",
    "                            #10 페이지 이상 \n",
    "                            else :\n",
    "                                next_button = browser.find_element(By.XPATH,'//*[@id=\"section_review\"]/div[3]/a[{0}]'.format( (page % 10) + 2)) #\n",
    "                                next_button.click()   \n",
    "                                # print('4번옵션')\n",
    "                        except:\n",
    "                            pass \n",
    "                        \n",
    "                        # 10페이지 이하 \n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[2] 2페이지\n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[3] 3페이지\n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[4] 4페이지 \n",
    "                        \n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[10] 10페이지 \n",
    "                        \n",
    "                        #10 페이지 이상 \n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[3] 12페이지\n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[4] 13페이지 \n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[10] 19페이지 \n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[11] 20페이지 \n",
    "                        \n",
    "                        # 10페이지 단위 \n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[11] 10페이지만 11이고\n",
    "                        \n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[12] 20페이지 부터는 12 \n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[12] 30페이지 \n",
    "                        # //*[@id=\"section_review\"]/div[3]/a[12] 40페이지\n",
    "                    \n",
    "                    # 전체 페이지 리뷰 완료했을시 \n",
    "                    ### 해당 상품 페이지 탭 닫기 \n",
    "                    browser.close()  \n",
    "                    browser.switch_to.window(browser.window_handles[0]) #첫번째 탭으로 돌아가기 (반드시 해야함)\n",
    "                    time.sleep(random.uniform(2,3))\n",
    "                else:\n",
    "                    continue  # '쇼핑몰별 최저가' 페이지 구조 아닌 경우 그냥 skip  \n",
    "            except : \n",
    "                #리뷰 리스트와 동일하게 에러가 나는 경우에는 에러리스트 추가 --> 나중에 문제 확인하고 수정해야 함 \n",
    "                error_dict = {}\n",
    "                error_dict['pdt_name'] = pdt_name \n",
    "                error_dict['pdt_page'] = pdt_page\n",
    "                error_dict['pdt_num'] = pdt_num\n",
    "                error_list.append(error_dict)\n",
    "                \n",
    "                #수집 에러가 나는 경우에도 해당 상품 페이지는 닫아야 함 \n",
    "                browser.close()  \n",
    "                browser.switch_to.window(browser.window_handles[0])\n",
    "                time.sleep(random.uniform(2,3))\n",
    "                continue \n",
    "        except NoSuchElementException:\n",
    "            # '쇼핑몰별 최저가' 구조 실패한 경우 다른 xpath 구조 시도하지 않고 넘어감\n",
    "            continue\n",
    "\n",
    "    # 여러 상품 보여주는 페이지: 다음 페이지 누르기 \n",
    "    # 1페이지랑 그 이후 페이지가 다름 \n",
    "    wait = WebDriverWait(browser, 5)\n",
    "    if pdt_page == 1: \n",
    "        next_page_button = browser.find_element(By.XPATH,'//*[@id=\"content\"]/div[1]/div[4]/a')\n",
    "        next_page_button.click()\n",
    "    else:\n",
    "        next_page_button = browser.find_element(By.XPATH,'//*[@id=\"content\"]/div[1]/div[4]/a[2]')\n",
    "        next_page_button.click()\n",
    "            ### 여기에도 try except문 써서 continue 하게 해줘보자 \n",
    "        '''\n",
    "        //*[@id=\"content\"]/div[1]/div[4]/a #1페이지 \n",
    "        //*[@id=\"content\"]/div[1]/div[4]/a[2] #2페이지부터 \n",
    "        //*[@id=\"content\"]/div[1]/div[4]/a[2]\n",
    "        //*[@id=\"content\"]/div[1]/div[4]/a[2]\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리가 아는 데이터 프레임이 나옴 \n",
    "df_review = pd.json_normalize(review_list)     \n",
    "df_review.loc[df_review['review'].isna()].shape\n",
    "df_review = df_review.drop(df_review[df_review['review'].isna()].index)\n",
    "\n",
    "df_error = pd.json_normalize(error_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdt_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>store</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운</td>\n",
       "      <td>5</td>\n",
       "      <td>주식회사 케이티알파</td>\n",
       "      <td>23.12.05.</td>\n",
       "      <td>카키 블랙 라벤더 이렇게 결국 사버렸네요 ㅋㅋ 라벤더는 좀 안어울릴수도 있겠가 반품...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운</td>\n",
       "      <td>5</td>\n",
       "      <td>주식회사 케이티알파</td>\n",
       "      <td>23.12.03.</td>\n",
       "      <td>빠르게 잘받았습니다. 우연히 채널돌리다 홈쇼핑에서 보고 괜찮아보여 주문했습니다. 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운</td>\n",
       "      <td>5</td>\n",
       "      <td>주식회사 케이티알파</td>\n",
       "      <td>23.11.08.</td>\n",
       "      <td>가볍고 보온성 좋은 캐시미어 찾다가 저렴한 가격으로 구매했어요. 아주 완전 부드럽지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운</td>\n",
       "      <td>5</td>\n",
       "      <td>주식회사 케이티알파</td>\n",
       "      <td>23.12.05.</td>\n",
       "      <td>카키 사고 결국 네이비, 라벤더도 구입. 네이비능 생각했던대로 무난해요. 핏은 카키...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운</td>\n",
       "      <td>5</td>\n",
       "      <td>신세계몰</td>\n",
       "      <td>23.11.18.</td>\n",
       "      <td>막스마라 스타일을 좋아하는데 비슷한 캐이프 디자인이 맘에 들어서 구매했어요. 핸드메...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191</td>\n",
       "      <td>5</td>\n",
       "      <td>롯데 기흥점 씨씨콜렉트</td>\n",
       "      <td>24.01.21.</td>\n",
       "      <td>가슴부분이 작아요 평소 55입어요. 컬러는 블루는 절대 아니고 그레이민트라이트 입니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6592</th>\n",
       "      <td>씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191</td>\n",
       "      <td>5</td>\n",
       "      <td>현대동대문 CC콜렉트</td>\n",
       "      <td>24.01.07.</td>\n",
       "      <td>색상찾기가 어려웠는데... 배송도 빠르고 잘 맞아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6593</th>\n",
       "      <td>씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191</td>\n",
       "      <td>5</td>\n",
       "      <td>롯데 기흥점 씨씨콜렉트</td>\n",
       "      <td>23.04.06.</td>\n",
       "      <td>털이.좀빠져.이거외엔.모양도예쁘고.좋은데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6594</th>\n",
       "      <td>씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191</td>\n",
       "      <td>5</td>\n",
       "      <td>롯데 기흥점 씨씨콜렉트</td>\n",
       "      <td>23.03.07.</td>\n",
       "      <td>가벼우면서도 포근하고 따뜻</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6595</th>\n",
       "      <td>씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191</td>\n",
       "      <td>5</td>\n",
       "      <td>롯데서울역점 씨씨콜렉트</td>\n",
       "      <td>24.01.09.</td>\n",
       "      <td>빠른배송 굳 가볍고 예쁨</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6295 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   pdt_name  rating         store       date  \\\n",
       "0      LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운       5    주식회사 케이티알파  23.12.05.   \n",
       "1      LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운       5    주식회사 케이티알파  23.12.03.   \n",
       "2      LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운       5    주식회사 케이티알파  23.11.08.   \n",
       "3      LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운       5    주식회사 케이티알파  23.12.05.   \n",
       "4      LE TROIS 23F W 이보영의 르투아 리얼 폭스퍼 롱구스다운       5          신세계몰  23.11.18.   \n",
       "...                                     ...     ...           ...        ...   \n",
       "6591  씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191       5  롯데 기흥점 씨씨콜렉트  24.01.21.   \n",
       "6592  씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191       5   현대동대문 CC콜렉트  24.01.07.   \n",
       "6593  씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191       5  롯데 기흥점 씨씨콜렉트  23.04.06.   \n",
       "6594  씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191       5  롯데 기흥점 씨씨콜렉트  23.03.07.   \n",
       "6595  씨씨콜렉트 폭스퍼 벨티드 구스다운 롱 패딩 점퍼 E224PSG191       5  롯데서울역점 씨씨콜렉트  24.01.09.   \n",
       "\n",
       "                                                 review  \n",
       "0     카키 블랙 라벤더 이렇게 결국 사버렸네요 ㅋㅋ 라벤더는 좀 안어울릴수도 있겠가 반품...  \n",
       "1     빠르게 잘받았습니다. 우연히 채널돌리다 홈쇼핑에서 보고 괜찮아보여 주문했습니다. 6...  \n",
       "2     가볍고 보온성 좋은 캐시미어 찾다가 저렴한 가격으로 구매했어요. 아주 완전 부드럽지...  \n",
       "3     카키 사고 결국 네이비, 라벤더도 구입. 네이비능 생각했던대로 무난해요. 핏은 카키...  \n",
       "4     막스마라 스타일을 좋아하는데 비슷한 캐이프 디자인이 맘에 들어서 구매했어요. 핸드메...  \n",
       "...                                                 ...  \n",
       "6591    가슴부분이 작아요 평소 55입어요. 컬러는 블루는 절대 아니고 그레이민트라이트 입니다  \n",
       "6592                       색상찾기가 어려웠는데... 배송도 빠르고 잘 맞아요  \n",
       "6593                             털이.좀빠져.이거외엔.모양도예쁘고.좋은데  \n",
       "6594                                     가벼우면서도 포근하고 따뜻  \n",
       "6595                                      빠른배송 굳 가볍고 예쁨  \n",
       "\n",
       "[6295 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.to_excel('naver_shopping_data2.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
